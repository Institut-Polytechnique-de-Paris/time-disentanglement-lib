{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bf9af4b-95e9-4c40-aa8e-b6eaebb6c7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "contains utilities to plot images and do related stuff\n",
    "\n",
    "Created on Fri Aug  6 21:05:58 2021\n",
    "\n",
    "@author: ricardo\n",
    "\"\"\"\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "\n",
    "def reshape_fortran(x, shape):\n",
    "    ''' perform a reshape in Matlab/Fortran style '''\n",
    "    if len(x.shape) > 0:\n",
    "        x = x.permute(*reversed(range(len(x.shape))))\n",
    "    return x.reshape(*reversed(shape)).permute(*reversed(range(len(shape))))\n",
    "\n",
    "\n",
    "def plotImage(dataY, nr, nc, L=None):\n",
    "    '''plots an image, a few bands (L by N)'''\n",
    "    # if isinstance(dataY, list):\n",
    "        # Y = torch.zeros((nr,nc,L))\n",
    "    if L == None:\n",
    "        L = dataY.shape[0]\n",
    "    plt.figure()\n",
    "    Yim = torch.reshape(dataY.T, (nc,nr,L))\n",
    "    plt.imshow(Yim[:,:,[10, 20, 30]])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plotEMs(M, thetitle='title'):\n",
    "    P = M.shape[1] # number of endmembers\n",
    "    L = M.shape[0] # number of bands\n",
    "    fig = plt.figure()\n",
    "    for i in range(P):\n",
    "        plt.plot(torch.linspace(1,L,L), M[:,i])\n",
    "    plt.title(thetitle, fontsize=12)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plotAbunds(A, nr, nc, thetitle='title', savepath=None):\n",
    "    ''' plots abundance maps, should be P by N '''\n",
    "    P = A.shape[0] # number of endmembers\n",
    "    N = A.shape[1] # number of pixels\n",
    "    A_cube = torch.reshape(A.T, (nc,nr,P))\n",
    "    fig, axs = plt.subplots(1, P)\n",
    "    for i in range(P):\n",
    "        axs[i].imshow(A_cube[:,:,i].T, cmap='jet', vmin=0, vmax=1) #cmap='gray'\n",
    "        axs[i].axis('off')\n",
    "    # plt.axis('off')\n",
    "    # axs[P-1].colorbar()\n",
    "    # fig = plt.figure()\n",
    "    # # plt.imshow(temp)\n",
    "    # plt.imshow(A_cube[:,:,0], cmap='gray', vmin=0, vmax=1)\n",
    "    # plt.colorbar()\n",
    "    plt.title(thetitle, fontsize=12)\n",
    "    if savepath is not None: # save a figure is specified\n",
    "        plt.savefig(savepath, dpi=300, format='pdf')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_ground_truth(A_true, Mgt_avg, nr, nc):\n",
    "    plotEMs(Mgt_avg, thetitle='ground truth')\n",
    "    plotAbunds(A_true, nr=nr, nc=nc, thetitle='ground truth')\n",
    "\n",
    "\n",
    "def compute_metrics(t_true, t_est):\n",
    "    RMSE = torch.sqrt(torch.sum((t_true-t_est)**2)/t_true.shape.numel())\n",
    "    NRSME = torch.sqrt(torch.sum((t_true-t_est)**2)/torch.sum(t_true**2))\n",
    "    return RMSE, NRSME\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Apr 15 21:49:06 2021\n",
    "\n",
    "# loads hyperspectral images\n",
    "\n",
    "@author: ricardo\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "import math\n",
    "import time\n",
    "import argparse\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import torch.distributions as td\n",
    "from scipy.io import loadmat, savemat\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# paths to the dataset files: -------------------------------------------------\n",
    "  \n",
    "path_dataset_DC1 = ['/tsi/data_education/Ladjal/koublal/open-source/IDNet/DATA/synth_DC1/data_ex_nl1.mat',\\\n",
    "                    '/tsi/data_education/Ladjal/koublal/open-source/IDNet/DATA/synth_DC1/extracted_bundles_nl_ex1.mat'] # synthetic data with nonlinear mixtures, with the BLMM\n",
    "\n",
    "path_dataset_DC2 = ['/tsi/data_education/Ladjal/koublal/open-source/IDNet/DATA/synth_DC2/alldata_ex_DC2.mat',\\\n",
    "                    '/tsi/data_education/Ladjal/koublal/open-source/IDNet/DATA/synth_DC2/extracted_bundles.mat'] # synthetic data with spectral variability\n",
    "\n",
    "path_dataset_Samson = ['/tsi/data_education/Ladjal/koublal/open-source/IDNet/DATA/real_Samson/alldata_real_Samson.mat',\\\n",
    "                       '/tsi/data_education/Ladjal/koublal/open-source/IDNet/DATA/real_Samson/extracted_bundles.mat']\n",
    "\n",
    "path_dataset_Jasper = ['/tsi/data_education/Ladjal/koublal/open-source/IDNet/DATA/real_Jasper/alldata_real_Jasper.mat',\\\n",
    "                       '/tsi/data_education/Ladjal/koublal/open-source/IDNet/DATA/real_Jasper/extracted_bundles.mat']\n",
    "\n",
    "path_dataset_Cuprite = ['/tsi/data_education/Ladjal/koublal/open-source/IDNet/DATA/real_Cuprite/alldata_real_Cuprite.mat',\\\n",
    "                        '/tsi/data_education/Ladjal/koublal/open-source/IDNet/DATA/real_Cuprite/extracted_bundles.mat']\n",
    "\n",
    "path_dataset_Houston = ['/tsi/data_education/Ladjal/koublal/open-source/IDNet/DATA/real_Houston/alldata_real_Houston.mat',\\\n",
    "                        '/tsi/data_education/Ladjal/koublal/open-source/IDNet/DATA/real_Houston/extracted_bundles.mat']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class dataNonlinear_synth():\n",
    "    def __init__(self):\n",
    "        '''data from synthetic example with nonlinear mixtures (BLMM)'''\n",
    "        mat_contents1 = loadmat(path_dataset_DC1[0]) # load image\n",
    "        mat_contents2 = loadmat(path_dataset_DC1[1]) # load image-extracted spectral libraries\n",
    "\n",
    "        self.L = mat_contents1['Mth'].shape[0]\n",
    "        self.P = mat_contents1['Mth'].shape[1]\n",
    "        self.N = mat_contents1['Y'].shape[1]\n",
    "        self.Nlib = mat_contents2['bundleLibs'][0,0].shape[1]\n",
    "        self.Y = torch.from_numpy(mat_contents1['Y']).type(torch.float32)\n",
    "        SNR = 40 \n",
    "        ssigma = (self.Y.mean())*(10**(-SNR/10))\n",
    "        \n",
    "        self.data_sup = []\n",
    "        for i in range(self.Nlib):\n",
    "            M_s = torch.zeros((self.L,self.P))\n",
    "            for j in range(self.P):\n",
    "                m_ij = mat_contents2['bundleLibs'][0,j][:,i]                \n",
    "                M_s[:,j] = torch.from_numpy(m_ij)            \n",
    "            for k in range(self.P):\n",
    "                a_s = torch.zeros((self.P,))\n",
    "                a_s[k] = 1.0\n",
    "                y_s = torch.mv(M_s,a_s) + ssigma * torch.randn((self.L,))\n",
    "                self.data_sup.append((y_s,M_s,a_s))\n",
    "                \n",
    "        self.data_unsup = []\n",
    "        for i in range(self.N):\n",
    "            self.data_unsup.append(torch.from_numpy(mat_contents1['Y'][:,i]).type(torch.float32))\n",
    "        self.A_cube_gt = torch.from_numpy(mat_contents1['A_cube'])\n",
    "        self.A_gt = self.A_cube_gt.permute(1,0,2).reshape((self.N,self.P)).T\n",
    "        self.Mavg_th = torch.from_numpy(mat_contents1['Mth'])\n",
    "        self.Mn_th = -0.5*torch.ones(self.L,self.P,self.N) \n",
    "        \n",
    "    def getdata(self):\n",
    "        return self.Y, self.data_sup, self.data_unsup\n",
    "    \n",
    "    def get_gt(self):\n",
    "        return self.A_gt, self.A_cube_gt, self.Mavg_th, self.Mn_th\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "class dataVariability_synth():\n",
    "    def __init__(self):\n",
    "        '''data from synthetic example with spectral variability'''\n",
    "        mat_contents1 = loadmat(path_dataset_DC2[0]) # load image\n",
    "        mat_contents2 = loadmat(path_dataset_DC2[1]) # load image-extracted spectral libraries\n",
    "\n",
    "        \n",
    "        self.L = mat_contents1['Mth'].shape[0]\n",
    "        self.P = mat_contents1['Mth'].shape[1]\n",
    "        self.N = mat_contents1['Mth'].shape[2]\n",
    "        self.Nlib = mat_contents2['bundleLibs'][0,0].shape[1]\n",
    "        self.Y = torch.from_numpy(mat_contents1['Y']).type(torch.float32)\n",
    "        \n",
    "        SNR = 40 \n",
    "        ssigma = (self.Y.mean())*(10**(-SNR/10))\n",
    "        \n",
    "        self.data_sup = []\n",
    "        for i in range(self.Nlib):\n",
    "            M_s = torch.zeros((self.L,self.P))\n",
    "            for j in range(self.P):\n",
    "                m_ij = mat_contents2['bundleLibs'][0,j][:,i]                \n",
    "                M_s[:,j] = torch.from_numpy(m_ij)            \n",
    "            for k in range(self.P):\n",
    "                a_s = torch.zeros((self.P,))\n",
    "                a_s[k] = 1.0\n",
    "                y_s = torch.mv(M_s,a_s) + ssigma * torch.randn((self.L,))\n",
    "                self.data_sup.append((y_s,M_s,a_s))\n",
    "                \n",
    "        self.data_unsup = []\n",
    "        for i in range(self.N):\n",
    "            self.data_unsup.append(torch.from_numpy(mat_contents1['Y'][:,i]).type(torch.float32))\n",
    "        self.A_gt = torch.from_numpy(mat_contents1['A'])\n",
    "        self.A_cube_gt = torch.from_numpy(mat_contents1['A_cube'])\n",
    "        self.Mavg_th = torch.from_numpy(mat_contents1['M_avg'])\n",
    "        self.Mn_th = torch.from_numpy(mat_contents1['Mth'])\n",
    "        \n",
    "    def getdata(self):\n",
    "        return self.Y, self.data_sup, self.data_unsup\n",
    "    \n",
    "    def get_gt(self):\n",
    "        return self.A_gt, self.A_cube_gt, self.Mavg_th, self.Mn_th\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class dataReal_real():\n",
    "    def __init__(self, ex_num=1):\n",
    "        '''data from real examples\n",
    "        ex_num \\in \\{1,2,3\\} = \\{Samson, Jasper Ridge, Cuprite\\}'''\n",
    "        \n",
    "        if ex_num == 1: # load data for the Samson image\n",
    "            mat_contents1 = loadmat(path_dataset_Samson[0]) # load image\n",
    "            mat_contents2 = loadmat(path_dataset_Samson[1]) # load image-extracted spectral libraries\n",
    "        \n",
    "        if ex_num == 2: # load data for the Jasper Ridge image\n",
    "            mat_contents1 = loadmat(path_dataset_Jasper[0]) # load image\n",
    "            mat_contents2 = loadmat(path_dataset_Jasper[1]) # load image-extracted spectral libraries\n",
    "        \n",
    "        if ex_num == 3: # load data for the Cuprite image\n",
    "            mat_contents1 = loadmat(path_dataset_Cuprite[0]) # load image\n",
    "            mat_contents2 = loadmat(path_dataset_Cuprite[1]) # load image-extracted spectral libraries\n",
    "\n",
    "        if ex_num == 4: # load data for the Cuprite image\n",
    "            mat_contents1 = loadmat(path_dataset_Houston[0]) # load image\n",
    "            mat_contents2 = loadmat(path_dataset_Houston[1]) # load image-extracted spectral libraries\n",
    "\n",
    "        self.L = mat_contents1['M0'].shape[0]\n",
    "        self.P = mat_contents1['M0'].shape[1]\n",
    "        self.N = mat_contents1['Y'].shape[1]\n",
    "        self.Nlib = mat_contents2['bundleLibs'][0,0].shape[1]\n",
    "        self.nr, self.nc = mat_contents1['Yim'].shape[0], mat_contents1['Yim'].shape[1]\n",
    "        self.Y = torch.from_numpy(mat_contents1['Y']).type(torch.float32)\n",
    "        \n",
    "        SNR = 40 \n",
    "        ssigma = (self.Y.mean())*(10**(-SNR/10))\n",
    "        \n",
    "        self.data_sup = []\n",
    "        for i in range(self.Nlib):\n",
    "            M_s = torch.zeros((self.L,self.P))\n",
    "            for j in range(self.P):\n",
    "                # m_ij = mat_contents2['bundleLibs'][0,j][:,i]  \n",
    "                m_ij = mat_contents2['bundleLibs'][0,j][:,i%mat_contents2['bundleLibs'][0,j].shape[1]] # circular shift\n",
    "                # m_ij = mat_contents1['M0'][:,j]\n",
    "                M_s[:,j] = torch.from_numpy(m_ij)\n",
    "            for k in range(self.P):\n",
    "                a_s = torch.zeros((self.P,))\n",
    "                a_s[k] = 1.0\n",
    "                y_s = torch.mv(M_s,a_s) + ssigma * torch.randn((self.L,))\n",
    "                self.data_sup.append((y_s,M_s,a_s))\n",
    "                \n",
    "        self.data_unsup = []\n",
    "        for i in range(self.N):\n",
    "            self.data_unsup.append(torch.from_numpy(mat_contents1['Y'][:,i]).type(torch.float32))\n",
    "        self.A_gt = -torch.ones((self.P,self.N))\n",
    "        self.A_cube_gt = -torch.ones((self.nr,self.nc,self.P))\n",
    "        self.Mavg_th = torch.from_numpy(mat_contents1['M0'])\n",
    "        self.Mn_th = -torch.ones((self.L,self.P,self.N))\n",
    "        \n",
    "    def getdata(self):\n",
    "        return self.Y, self.data_sup, self.data_unsup\n",
    "    \n",
    "    def get_gt(self):\n",
    "        return self.A_gt, self.A_cube_gt, self.Mavg_th, self.Mn_th\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class dataset_maker(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_opt = 1):\n",
    "        '''initialize variables and select which data to load\n",
    "        data_opt = 1 : synthetic nonlinear mixture (DC1, with the BLMM) \n",
    "        data_opt = 2 : synthetic example with variability (DC2)\n",
    "        data_opt = 3--5 : real data examples (samson, jasper, cuprite)\n",
    "        '''\n",
    "        self.data_sup = []\n",
    "        self.data_unsup = []\n",
    "        # the following is the data ground truth:\n",
    "        self.A_u = [] # ground truth abundance matrix (P * N)\n",
    "        self.A_u_cube = [] # ground truth abundance cube (nr * nc * P) \n",
    "        self.M_u_avg = [] # ground truth 'average' or 'reference' EM matrix\n",
    "        self.M_u_ppx = [] # ground truth EM matrices for each pixel\n",
    "        self.Y = [] # observed hyperspectral image (L * N)\n",
    "        \n",
    "        self.data_opt = data_opt # store data index for later access\n",
    "        if data_opt == 1:\n",
    "            self.NonlinearData_synth()\n",
    "        if data_opt == 2: \n",
    "            self.VariabilityData_synth()\n",
    "        if data_opt in range(3,7):\n",
    "            self.RealData_real(data_opt-2)\n",
    "        \n",
    "        if len(self.data_sup) < len(self.data_unsup):\n",
    "            self.flag_unsup_is_bigger = True\n",
    "        else:\n",
    "            self.flag_unsup_is_bigger = False\n",
    "            \n",
    "            \n",
    "\n",
    "    def NonlinearData_synth(self):\n",
    "        myDatator = dataNonlinear_synth()\n",
    "        self.Y, self.data_sup, self.data_unsup = myDatator.getdata()\n",
    "        self.A_u, self.A_u_cube, self.M_u_avg, self.M_u_ppx = myDatator.get_gt()\n",
    "    \n",
    "    def VariabilityData_synth(self):\n",
    "        myDatator = dataVariability_synth()\n",
    "        self.Y, self.data_sup, self.data_unsup = myDatator.getdata()\n",
    "        self.A_u, self.A_u_cube, self.M_u_avg, self.M_u_ppx = myDatator.get_gt()\n",
    "    \n",
    "    def RealData_real(self, k):\n",
    "        '''k \\in {1,2,3}'''\n",
    "        myDatator = dataReal_real(k)\n",
    "        self.Y, self.data_sup, self.data_unsup = myDatator.getdata()\n",
    "        self.A_u, self.A_u_cube, self.M_u_avg, self.M_u_ppx = myDatator.get_gt()\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        # take the maximum length between the supervised and unsupervised datasets\n",
    "        return max(len(self.data_sup),len(self.data_unsup))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # now, idx corresponds to the index among the largest (sup or unsup) dataset.\n",
    "        # We can multiply it by the ratio between the smallest and the largest datset\n",
    "        # and round down to an integer, to obtain the corresponding index for the \n",
    "        # smaller dataset\n",
    "        if self.flag_unsup_is_bigger:\n",
    "            idx_sup = int(np.floor(idx*len(self.data_sup)/len(self.data_unsup)))\n",
    "            idx_unsup = idx\n",
    "        else:\n",
    "            idx_sup = idx\n",
    "            idx_unsup = int(np.floor(idx*len(self.data_unsup)/len(self.data_sup)))\n",
    "        \n",
    "        # return tuples? (y) and (y,M,a)\n",
    "        return self.data_unsup[idx_unsup], self.data_sup[idx_sup]\n",
    "    \n",
    "    \n",
    "    def plot_training_EMs(self, EM_idx=-1):\n",
    "        '''small method to plot EMs in the training dataset'''\n",
    "        L, P, Nsamp = self.data_sup[0][1].shape[0], self.data_sup[0][1].shape[1], len(self.data_sup)\n",
    "        M_train = torch.zeros((L,P,Nsamp))\n",
    "        for i in range(Nsamp):\n",
    "            M_train[:,:,i] = self.data_sup[0][1]\n",
    "        if EM_idx == -1:\n",
    "            fig, axs = plt.subplots(1, P)\n",
    "            for i in range(P):\n",
    "                axs[i].plot(torch.squeeze(M_train[:,i,:]))\n",
    "        else:\n",
    "            plt.figure()\n",
    "            plt.plot(torch.squeeze(M_train[:,EM_idx,:]))\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cff17789-1ea5-43d8-a616-8e2b29c9b896",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "contains utilities to plot images and do related stuff\n",
    "\n",
    "Created on Fri Aug  6 21:05:58 2021\n",
    "\n",
    "@author: ricardo\n",
    "\"\"\"\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "\n",
    "def reshape_fortran(x, shape):\n",
    "    ''' perform a reshape in Matlab/Fortran style '''\n",
    "    if len(x.shape) > 0:\n",
    "        x = x.permute(*reversed(range(len(x.shape))))\n",
    "    return x.reshape(*reversed(shape)).permute(*reversed(range(len(shape))))\n",
    "\n",
    "\n",
    "def plotImage(dataY, nr, nc, L=None):\n",
    "    '''plots an image, a few bands (L by N)'''\n",
    "    # if isinstance(dataY, list):\n",
    "        # Y = torch.zeros((nr,nc,L))\n",
    "    if L == None:\n",
    "        L = dataY.shape[0]\n",
    "    plt.figure()\n",
    "    Yim = torch.reshape(dataY.T, (nc,nr,L))\n",
    "    plt.imshow(Yim[:,:,[10, 20, 30]])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plotEMs(M, thetitle='title', savepath = None):\n",
    "    P = M.shape[1] # number of endmembers\n",
    "    L = M.shape[0] # number of bands\n",
    "    fig = plt.figure()\n",
    "    for i in range(P):\n",
    "        plt.plot(torch.linspace(1,L,L), M[:,i])\n",
    "    plt.title(thetitle, fontsize=12)\n",
    "    if savepath is not None: # save a figure is specified\n",
    "        plt.savefig(savepath, dpi=300, format='pdf')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plotAbunds(A, nr, nc, thetitle='title', savepath=None):\n",
    "    ''' plots abundance maps, should be P by N '''\n",
    "    P = A.shape[0] # number of endmembers\n",
    "    N = A.shape[1] # number of pixels\n",
    "    A_cube = torch.reshape(A.T, (nc,nr,P))\n",
    "    fig, axs = plt.subplots(1, P)\n",
    "    for i in range(P):\n",
    "        axs[i].imshow(A_cube[:,:,i].T, cmap='jet', vmin=0, vmax=1) #cmap='gray'\n",
    "        axs[i].axis('off')\n",
    "    # plt.axis('off')\n",
    "    # axs[P-1].colorbar()\n",
    "    # fig = plt.figure()\n",
    "    # # plt.imshow(temp)\n",
    "    # plt.imshow(A_cube[:,:,0], cmap='gray', vmin=0, vmax=1)\n",
    "    # plt.colorbar()\n",
    "    plt.title(thetitle, fontsize=12)\n",
    "    if savepath is not None: # save a figure is specified\n",
    "        plt.savefig(savepath, dpi=300, format='pdf')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_ground_truth(A_true, Mgt_avg, nr, nc):\n",
    "    plotEMs(Mgt_avg, thetitle='ground truth')\n",
    "    plotAbunds(A_true, nr=nr, nc=nc, thetitle='ground truth')\n",
    "\n",
    "\n",
    "def compute_metrics(t_true, t_est):\n",
    "    RMSE = torch.sqrt(torch.sum((t_true-t_est)**2)/t_true.shape.numel())\n",
    "    NRSME = torch.sqrt(torch.sum((t_true-t_est)**2)/torch.sum(t_true**2))\n",
    "    return RMSE, NRSME\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b452f04f-ff27-4cba-b3b2-688cea3b1764",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Apr 13 20:31:15 2021\n",
    "\n",
    "@author: ricardo\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from __future__ import print_function\n",
    "import math\n",
    "import time\n",
    "import argparse\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import torch.distributions as td\n",
    "from scipy.io import loadmat, savemat\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# for reproducibility\n",
    "# device = torch.device(\"cuda\")\n",
    "device = torch.device(\"cpu\")\n",
    "seed = 1\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "\n",
    "\n",
    "class IDNet(nn.Module):\n",
    "    ''' Class containing the whole architecture of ID-Net'''\n",
    "    def __init__(self, P, L, H = 2):\n",
    "        super(IDNet, self).__init__()\n",
    "        \n",
    "        # problem parameters ----------------------------------------\n",
    "        self.P = P # number of endmembers\n",
    "        self.H = H # latent EM space dimension\n",
    "        self.L = L # number of bands\n",
    "        \n",
    "        # gains on the networks nonlinear parts ---------------------\n",
    "        self.gain_nlin_a = 0.1\n",
    "        self.gain_nlin_y = 0.1\n",
    "        \n",
    "        # (importance) sampling sizes -------------------------------\n",
    "        self.K1 = 1\n",
    "        self.K2 = 5\n",
    "        \n",
    "        \n",
    "        \n",
    "        # variables -------------------------------------------------\n",
    "        # Variance of the pixel noise \n",
    "        self.fcy_std = nn.Linear(1, 1)\n",
    "        \n",
    "        # Parameters from the EM distribution, see also torch.nn.ParameterList()\n",
    "        self.fcMz_mu  = torch.nn.ModuleList();\n",
    "        self.fcMz_std = torch.nn.ModuleList();\n",
    "        self.fcMz_std2 = torch.nn.ModuleList();\n",
    "        for i in range(0, self.P):\n",
    "            self.fcMz_mu.append(nn.Sequential(\n",
    "                  nn.Linear(self.H, max(math.ceil(self.L/10),self.H+1)),\n",
    "                  nn.ReLU(),\n",
    "                  nn.Linear(max(math.ceil(self.L/10),self.H+1), max(math.ceil(self.L/4),self.H+2)+3),\n",
    "                  nn.ReLU(),\n",
    "                  nn.Linear(max(math.ceil(self.L/4),self.H+2)+3, math.ceil(1.2*self.L)+5),\n",
    "                  nn.ReLU(),\n",
    "                  nn.Linear(math.ceil(1.2*self.L)+5, self.L),\n",
    "                  nn.Sigmoid() ))\n",
    "            self.fcMz_std.append(nn.Sequential(\n",
    "                  nn.Linear(self.H, 1),\n",
    "                  nn.ReLU() ))\n",
    "            self.fcMz_std2.append(nn.Linear(1, 1))\n",
    "        \n",
    "        \n",
    "        # Parameters of the recognition model for Z|y\n",
    "        self.fcZy_mu  = torch.nn.ModuleList();\n",
    "        self.fcZy_std = torch.nn.ModuleList();\n",
    "        for i in range(0, self.P):\n",
    "            self.fcZy_mu.append(nn.Sequential(\n",
    "                  nn.Linear(self.L, 5*self.H),\n",
    "                  nn.ReLU(),\n",
    "                  nn.Linear(5*self.H,2*self.H),\n",
    "                  nn.ReLU(),\n",
    "                  nn.Linear(2*self.H,self.H) ))\n",
    "            \n",
    "        for i in range(0, self.P): # share parameters for the covariance\n",
    "            self.fcZy_std.append(nn.Sequential(\n",
    "                  self.fcZy_mu[i][0],\n",
    "                  nn.ReLU(),\n",
    "                  self.fcZy_mu[i][2],\n",
    "                  nn.ReLU(),\n",
    "                  nn.Linear(2*self.H,2*self.H),\n",
    "                  nn.ReLU(),\n",
    "                  nn.Linear(2*self.H,2*self.H),\n",
    "                  nn.ReLU(),\n",
    "                  nn.Linear(2*self.H,self.H) ))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Precision of the abundance posterior distribution a|M,y\n",
    "        self.fca_std = nn.Sequential(\n",
    "                  nn.Linear(1, 1),\n",
    "                  nn.ReLU())\n",
    "        self.fca_std2 = nn.Linear(1, 1)\n",
    "        \n",
    "        \n",
    "        # nonlinear part of the neural net that estimates the alphas (Dirichlet params)\n",
    "        self.fca_My_alphas = nn.Sequential(\n",
    "                  nn.Linear(self.L, 2*self.L),\n",
    "                  nn.ReLU(),\n",
    "                  nn.Linear(2*self.L, round(0.5*self.L)),\n",
    "                  nn.ReLU(),\n",
    "                  nn.Linear(round(0.5*self.L), round(0.25*self.L)),\n",
    "                  nn.ReLU(),\n",
    "                  nn.Linear(round(0.25*self.L), 4*self.P),\n",
    "                  nn.ReLU(),\n",
    "                  nn.Linear(4*self.P, self.P))\n",
    "        \n",
    "\n",
    "        \n",
    "        self.fcy_Ma_nlin = nn.Sequential(\n",
    "                  nn.Linear(self.P*(self.L+1), self.P*self.L),\n",
    "                  nn.ReLU(),\n",
    "                  nn.Linear(self.P*self.L, self.L),\n",
    "                  nn.ReLU(),\n",
    "                  nn.Linear(self.L, self.L),\n",
    "                  nn.ReLU(),\n",
    "                  nn.Linear(self.L, self.L))\n",
    "        \n",
    "        \n",
    "        \n",
    "        # related to abundance sparsity\n",
    "        self.fca_llambda = nn.Linear(1, 1)\n",
    "        self.K_iters_LISTA = 10; # number of LISTA iterations\n",
    "        self.fca_llambda3 = nn.Linear(1, self.K_iters_LISTA)\n",
    "        \n",
    "        self.fca_Rtilde = nn.Sequential(\n",
    "                  nn.Linear(self.P, self.P),\n",
    "                  nn.ReLU())\n",
    "        self.fca_prior = nn.Linear(1, self.P)\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "    def UnrolledNetAlphas(self, y, M, K_iter=10):\n",
    "        # LISTA-type network ---------------------------------\n",
    "        llambda  = 0.01*torch.exp(self.fca_llambda(torch.tensor([float(1)])))\n",
    "        llambda3 = 0.01*torch.exp(self.fca_llambda3(torch.tensor([float(1)])))\n",
    "        alpha = torch.bmm(torch.linalg.pinv(M), y.unsqueeze(2)).squeeze(2)\n",
    "        for i in range(self.K_iters_LISTA):\n",
    "            alpha = alpha - llambda3[i]*torch.bmm(M.permute(0,2,1), \\\n",
    "                    torch.bmm(M, alpha.unsqueeze(2))-y.unsqueeze(2)).squeeze(2)\n",
    "            alpha = torch.nn.functional.relu(alpha - llambda3[i]*llambda, inplace=False) # soft shrinkage and project to nonnegative orthant\n",
    "        alpha_hat = alpha\n",
    "        return alpha_hat\n",
    "    \n",
    "    def compute_log_p_Gaussian(self, sigmas, mus, z):\n",
    "        ''' computes log(p(z)), for p=N(mus,diag(sigmas)), with batched data\n",
    "        sigmas : batch * K (variances, diagonal covariance matrix)\n",
    "        mus : batch * K (means)\n",
    "        z : batch * K (smaples) '''\n",
    "        K = z.shape[1]\n",
    "        exppart = - 0.5 * (((mus-z)/sigmas)*(mus-z)).sum(1)\n",
    "        constpart = -0.5*K*torch.log(2*torch.tensor(math.pi)) \\\n",
    "                    -0.5*torch.log(sigmas).sum(1)\n",
    "        return constpart + exppart\n",
    "    \n",
    "    \n",
    "    \n",
    "    def samp_q_Z_y(self, y, batch_size, K1):\n",
    "        ''' returns a reparametrized sample from q(Z|y) in batch form\n",
    "        y : batch_size * L (pixels)'''\n",
    "        # compute means and covariances ------------\n",
    "        Z_y_mean  = torch.zeros((batch_size*1,self.H,self.P))\n",
    "        Z_y_sigma = torch.zeros((batch_size*1,self.H,self.P))\n",
    "        for i in range(self.P):\n",
    "            Z_y_mean[:,:,i] = self.fcZy_mu[i](y)\n",
    "            Z_y_sigma[:,:,i] = torch.exp(self.fcZy_std[i](y)) # variances\n",
    "        \n",
    "        # replicate the means and variances for all MC samples (better than doing it on y)\n",
    "        Z_y_mean = torch.kron(torch.ones((K1,1,1)), Z_y_mean)\n",
    "        Z_y_sigma = torch.kron(torch.ones((K1,1,1)), Z_y_sigma)\n",
    "        \n",
    "        # sample epsilon from N(0,1)\n",
    "        epsilon1 = torch.normal(torch.zeros((batch_size*K1,self.H,self.P)), 1)\n",
    "        Z_y_samp = torch.sqrt(Z_y_sigma) * epsilon1 + Z_y_mean # reparametrization\n",
    "        return Z_y_mean, Z_y_sigma, Z_y_samp\n",
    "    \n",
    "    \n",
    "    def samp_q_M_Z(self, Z, batch_size, K1):\n",
    "        ''' returns a reparametrized sample from q(M|Z) in batch form\n",
    "        Z : (batch_sizeK1) * H * P (latent EM representations)'''\n",
    "        M_Z_mean  = torch.zeros((batch_size*K1,self.L,self.P))\n",
    "        M_Z_sigma = torch.zeros((batch_size*K1,self.L,self.P))\n",
    "        for i in range(self.P):\n",
    "            M_Z_mean[:,:,i] = self.fcMz_mu[i](Z[:,:,i]) # Z = Z_y_samp\n",
    "            M_Z_sigma[:,:,i] = torch.ones((batch_size*K1,self.L)) * \\\n",
    "                        0.01*torch.exp(self.fcMz_std2[i](torch.tensor([float(1)])))\n",
    "        \n",
    "        # sample epsilon from N(0,1)\n",
    "        epsilon2 = torch.normal(torch.zeros((batch_size*K1,self.L,self.P)), 1)\n",
    "        M_Z_samp = torch.sqrt(M_Z_sigma) * epsilon2 + M_Z_mean # reparametrization\n",
    "        return M_Z_mean, M_Z_sigma, M_Z_samp\n",
    "    \n",
    "    \n",
    "    def samp_q_a_My(self, M, y, batch_size, K1, compute_nlin_deg=False):\n",
    "        ''' returns a reparametrized sample from q(a|M,Z) in batch form\n",
    "        M : (batch_sizeK1) * L * P (sampled EMs)\n",
    "        y : batch_size * L (pixels)'''\n",
    "        y = torch.kron(torch.ones((K1,1)), y)\n",
    "        # compute alphas\n",
    "        K = 10 + 100*torch.exp(self.fca_std2(torch.tensor([float(1)])))\n",
    "        alphas_lin  = self.UnrolledNetAlphas(y, M) # lista, sparse linear part\n",
    "        alphas_nlin = self.gain_nlin_a*self.fca_My_alphas(y) # nonlinear part\n",
    "        alphas      = alphas_lin + alphas_nlin # add them together\n",
    "        # project to nonnegative orthant:\n",
    "        alphas_hat = 1e-16 + K*torch.nn.functional.relu(alphas, inplace=False) \n",
    "        \n",
    "        # now sample the abundances\n",
    "        q_a_My = []\n",
    "        a_Zy_samp = torch.zeros((batch_size*K1,self.P))\n",
    "        for i in range(batch_size*K1):\n",
    "            q_a_My.append(td.Dirichlet(alphas_hat[i,:]))\n",
    "            a_Zy_samp[i,:] = q_a_My[i].rsample()\n",
    "        \n",
    "        # if true, compute the rati of the energy of the nonlinear term in the abundance \n",
    "        # estimation compared to the energy of the full term\n",
    "        if compute_nlin_deg is True:\n",
    "            a_nlin_deg = torch.sqrt(torch.sum(alphas_nlin.detach()**2, dim=1)) \\\n",
    "                       /( torch.sqrt(torch.sum(alphas_lin.detach()**2, dim=1)) \\\n",
    "                        + torch.sqrt(torch.sum(alphas_nlin.detach()**2, dim=1)) )\n",
    "            return q_a_My, alphas_hat, a_Zy_samp, a_nlin_deg\n",
    "        \n",
    "        return q_a_My, alphas_hat, a_Zy_samp\n",
    "    \n",
    "    \n",
    "    \n",
    "    def unmix(self, Y):\n",
    "        ''' perform unmixing on the whole image Y (bands*pixels)'''\n",
    "        N = Y.shape[1]\n",
    "        M_avg, _, _ = self.samp_q_M_Z(Z=torch.zeros((1,self.H,self.P)), batch_size=1, K1=1)\n",
    "        Z_y_mean, Z_y_sigma, Z_y_samp = self.samp_q_Z_y(Y.T, batch_size=N, K1=1)\n",
    "        Mn_est, M_Z_sigma, M_Z_samp = self.samp_q_M_Z(Z=Z_y_samp, batch_size=N, K1=1)\n",
    "        q_a_My, alphas, a_Zy_samp, a_nlin_deg = self.samp_q_a_My(M=Mn_est, y=Y.T, batch_size=N, K1=1, compute_nlin_deg=True)\n",
    "        A_est = (alphas/torch.kron(torch.ones(1,self.P), alphas.sum(dim=1).unsqueeze(1))).T\n",
    "        # compute the reconstructed image\n",
    "        Y_rec = nn.functional.relu(torch.bmm(Mn_est, A_est.T.unsqueeze(2)).squeeze() \\\n",
    "            + self.gain_nlin_y*self.fcy_Ma_nlin(torch.cat((Mn_est.reshape((N,self.L*self.P)),A_est.T), dim=1))).T # nonlinear part\n",
    "        return A_est, Mn_est.permute(1,2,0), M_avg.squeeze(), Y_rec, a_nlin_deg\n",
    "\n",
    "    \n",
    "    def forward(self, x_data):\n",
    "        # x_data should have the supervised and semi-supervised part of the data (will be twiced)\n",
    "        # it is a list, [unsup sup]\n",
    "        # unsup is the bath_size * L pixels\n",
    "        # sup is another list, [y M a], where y,M,a are bath_size * otherdims tensors\n",
    "        \n",
    "        # Get data -------------------------------\n",
    "        batch_size = x_data[0].shape[0]\n",
    "        \n",
    "        y_unsup = x_data[0].to(device) # batch * L\n",
    "        y_sup = x_data[1][0].to(device) # batch * L\n",
    "        M_sup = x_data[1][1].to(device)\n",
    "        a_sup = x_data[1][2].to(device)\n",
    "\n",
    "        # Print the shapes\n",
    "        # print(f\"y_unsup shape: {y_unsup.shape}\")\n",
    "        # print(f\"y_sup shape: {y_sup.shape}\")\n",
    "        # print(f\"M_sup shape: {M_sup.shape}\")\n",
    "        # print(f\"a_sup shape: {a_sup.shape}\")\n",
    "\n",
    "\n",
    "        \n",
    "                \n",
    "        # construct latent PDFs and some parameters ------------------\n",
    "        a_prior_par = torch.ones(self.P,)\n",
    "        p_a = td.Dirichlet(a_prior_par)\n",
    "        sigma_noise_y = 0.01*torch.exp(self.fcy_std(torch.tensor([float(1)]))) # variance of the pixels noise (per band)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # first unsupervised part --------------------------------------------\n",
    "        K1 = self.K1\n",
    "        \n",
    "        # initialize\n",
    "        log_probs_unsup = dict()\n",
    "        log_py_Ma = torch.zeros((batch_size*K1))\n",
    "        log_pM_Z  = torch.zeros((batch_size*K1))\n",
    "        log_pZ    = torch.zeros((batch_size*K1))\n",
    "        log_pa    = torch.zeros((batch_size*K1))\n",
    "        log_qZ_y  = torch.zeros((batch_size*K1))\n",
    "        log_qM_Z  = torch.zeros((batch_size*K1))\n",
    "        log_qa_My = torch.zeros((batch_size*K1))\n",
    "        alphas_unsup = torch.zeros((self.P,batch_size*K1))\n",
    "        \n",
    "        # reparametrizeable sampling ---------------------------\n",
    "        # first sample the Z, then from M, then from a\n",
    "        Z_y_mean, Z_y_sigma, Z_y_samp = self.samp_q_Z_y(y_unsup, batch_size, K1) # q(Z|y)\n",
    "        M_Z_mean, M_Z_sigma, M_Z_samp = self.samp_q_M_Z(Z_y_samp, batch_size, K1) # q(M|Z)\n",
    "        q_a_My, alphas, a_Zy_samp = self.samp_q_a_My(M_Z_samp, y_unsup, batch_size, K1) # q(a|M,y)\n",
    "\n",
    "                \n",
    "        # compute the parameters of p(y|M,a)\n",
    "        y_Ma_sigma = sigma_noise_y * torch.ones((batch_size*K1,self.L))\n",
    "        y_Ma_mean = torch.bmm(M_Z_samp, a_Zy_samp.unsqueeze(2)).squeeze() # linear part\n",
    "        y_Ma_mean = y_Ma_mean + self.gain_nlin_y*self.fcy_Ma_nlin(torch.cat((M_Z_samp.reshape((batch_size*K1,self.L*self.P)),a_Zy_samp), dim=1)) # nonlinear part\n",
    "        y_Ma_mean = nn.functional.relu(y_Ma_mean)\n",
    "        \n",
    "        \n",
    "        # now compute the log-probabilities\n",
    "        y_unsup_repl = torch.kron(torch.ones((K1,1)),y_unsup) # replicate across MC samples\n",
    "        log_py_Ma = self.compute_log_p_Gaussian(y_Ma_sigma, y_Ma_mean, y_unsup_repl)\n",
    "        for k in range(self.P):\n",
    "            log_pM_Z = log_pM_Z + self.compute_log_p_Gaussian(M_Z_sigma[:,:,k], M_Z_mean[:,:,k], M_Z_samp[:,:,k]) # p_M_Z[k].log_prob(M_unsup[:,k])\n",
    "            log_pZ   = log_pZ   + self.compute_log_p_Gaussian(torch.ones((batch_size*K1,self.H)), torch.zeros((batch_size*K1,self.H)), Z_y_samp[:,:,k]) # p_z.log_prob(Z_unsup[:,k])\n",
    "            log_qZ_y = log_qZ_y + self.compute_log_p_Gaussian(Z_y_sigma[:,:,k], Z_y_mean[:,:,k], Z_y_samp[:,:,k]) # q_Z_y[k].log_prob(Z_unsup[:,k])\n",
    "        log_qM_Z = log_pM_Z # we assume q=p for M|Z\n",
    "        \n",
    "        for i in range(batch_size*K1):\n",
    "            log_qa_My[i] = q_a_My[i].log_prob(a_Zy_samp[i,:]+1e-16) \n",
    "            log_pa[i]    = p_a.log_prob(a_Zy_samp[i,:]+1e-16)\n",
    "        \n",
    "        # store alphas\n",
    "        alphas_unsup = alphas.T\n",
    "         \n",
    "        \n",
    "        # reorder (useless)\n",
    "        log_py_Ma = reshape_fortran(log_py_Ma, (batch_size,K1))\n",
    "        log_pM_Z  = reshape_fortran(log_pM_Z,  (batch_size,K1))\n",
    "        log_pZ    = reshape_fortran(log_pZ,    (batch_size,K1))\n",
    "        log_pa    = reshape_fortran(log_pa,    (batch_size,K1))\n",
    "        log_qZ_y  = reshape_fortran(log_qZ_y,  (batch_size,K1))\n",
    "        log_qM_Z  = reshape_fortran(log_qM_Z,  (batch_size,K1))\n",
    "        log_qa_My = reshape_fortran(log_qa_My, (batch_size,K1))\n",
    "        alphas_unsup = reshape_fortran(alphas_unsup, (self.P,batch_size,K1))\n",
    "        \n",
    "                \n",
    "        # now store the log probs of the unspervised part\n",
    "        log_probs_unsup = {'log_py_Ma':log_py_Ma, 'log_pM_Z':log_pM_Z,\n",
    "                           'log_pZ':log_pZ, 'log_qZ_y':log_qZ_y,\n",
    "                           'log_qM_Z':log_qM_Z, 'log_qa_My':log_qa_My, 'log_pa':log_pa}\n",
    "        \n",
    "        \n",
    "        \n",
    "        # now for the semi-supervised part ------------------------------------\n",
    "        K2 = self.K2\n",
    "        \n",
    "        # initialize\n",
    "        log_probs_sup = dict()\n",
    "        log_py_Ma  = torch.zeros((batch_size*1)) # constant for MC samples K2\n",
    "        log_pM_Z   = torch.zeros((batch_size*K2))\n",
    "        log_pZ     = torch.zeros((batch_size*K2))\n",
    "        log_pa     = torch.zeros((batch_size*1)) # constant for MC samples K2\n",
    "        log_qZ_y   = torch.zeros((batch_size*K2))\n",
    "        log_qM_Z   = torch.zeros((batch_size*K2))\n",
    "        log_qa_My  = torch.zeros((batch_size*1)) # constant for MC samples K2\n",
    "        log_omegas = torch.zeros((batch_size,K2)) # the log-importante weights\n",
    "        alphas_sup = torch.zeros((self.P,batch_size*K2))\n",
    "        \n",
    "        \n",
    "        # reparametrizeable sampling ---------------------------\n",
    "        # first sample the Z, then from M, then from a\n",
    "        Z_y_mean, Z_y_sigma, Z_y_samp = self.samp_q_Z_y(y_sup, batch_size, K2)\n",
    "        M_Z_mean, M_Z_sigma, M_Z_samp = self.samp_q_M_Z(Z_y_samp, batch_size, K2)\n",
    "        q_a_My, alphas, a_Zy_samp = self.samp_q_a_My(M_sup, y_sup, batch_size, 1) # compute once and replicate later\n",
    "\n",
    "        \n",
    "        # compute the parameters of p(y|M,a)\n",
    "        y_Ma_sigma = sigma_noise_y * torch.ones((batch_size,self.L))\n",
    "        y_Ma_mean = torch.bmm(M_sup, a_sup.unsqueeze(2)).squeeze() # linear part\n",
    "        y_Ma_mean = y_Ma_mean + self.gain_nlin_y*self.fcy_Ma_nlin(torch.cat((M_sup.reshape((batch_size,self.L*self.P)),a_sup), dim=1)) # nonlinear part\n",
    "        y_Ma_mean = nn.functional.relu(y_Ma_mean)\n",
    "        \n",
    "        \n",
    "        # replicate M_sup to match MC samples\n",
    "        M_sup_repl = torch.kron(torch.ones((K2,1,1)), M_sup)\n",
    "        \n",
    "        # now compute the log-probabilities\n",
    "        log_py_Ma = self.compute_log_p_Gaussian(y_Ma_sigma, y_Ma_mean, y_sup)\n",
    "        for k in range(self.P):\n",
    "            log_pM_Z = log_pM_Z + self.compute_log_p_Gaussian(M_Z_sigma[:,:,k], M_Z_mean[:,:,k], M_sup_repl[:,:,k]) # p_M_Z[k].log_prob(M_sup[:,k])\n",
    "            log_pZ   = log_pZ   + self.compute_log_p_Gaussian(torch.ones((batch_size*K2,self.H)), torch.zeros((batch_size*K2,self.H)), Z_y_samp[:,:,k]) # p_z.log_prob(Z_sup[:,k])\n",
    "            log_qZ_y = log_qZ_y + self.compute_log_p_Gaussian(Z_y_sigma[:,:,k], Z_y_mean[:,:,k], Z_y_samp[:,:,k]) # q_Z_y[k].log_prob(Z_sup[:,k])\n",
    "        log_qM_Z = log_pM_Z # we assume q=p for M|Z\n",
    "        \n",
    "        for i in range(batch_size*1):\n",
    "            log_qa_My[i] = q_a_My[i].log_prob(a_Zy_samp[i,:]+1e-16) \n",
    "            log_pa[i]    = p_a.log_prob(a_Zy_samp[i,:]+1e-16)\n",
    "        \n",
    "        \n",
    "        # replicate log_p values that were constant across MC samples K2\n",
    "        log_py_Ma = torch.kron(torch.ones((K2,1)), log_py_Ma)\n",
    "        log_qa_My = torch.kron(torch.ones((K2,1)), log_qa_My)\n",
    "        log_pa    = torch.kron(torch.ones((K2,1)), log_pa)\n",
    "        \n",
    "        # store alphas\n",
    "        alphas_sup = torch.kron(torch.ones((K2,1)), alphas).T\n",
    "        \n",
    "        \n",
    "        # now compute the log-importance weights\n",
    "        log_omegas = reshape_fortran(log_qM_Z, (batch_size,K2))\n",
    "        \n",
    "        # for k in range(0,self.P):\n",
    "        #     log_omegas[i,j] = log_omegas[i,j] + q_M_Z[k].log_prob(M_sup[i,:,k]) # compute log[ q(M(i)|Z(j)) ]\n",
    "        # #omegas[i,j] = torch.exp(omegas[i,j]) # compute q(M(i)|Z(j)) --- don't do this to void numerical problems!\n",
    "\n",
    "        # normalize the importance weights by their sum : omega[i,j] <- omega[i,j]/sum_j(omega[i,j])\n",
    "        omegas_nrmlzd = torch.softmax(log_omegas, dim=1) # use the softmax to compute the exponential and\n",
    "                                                         # normalize the omegas by their sum in a single step\n",
    "        \n",
    "        # reorder (useless)\n",
    "        log_py_Ma = reshape_fortran(log_py_Ma, (batch_size,K2))\n",
    "        log_pM_Z  = reshape_fortran(log_pM_Z,  (batch_size,K2))\n",
    "        log_pZ    = reshape_fortran(log_pZ,    (batch_size,K2))\n",
    "        log_pa    = reshape_fortran(log_pa,    (batch_size,K2))\n",
    "        log_qZ_y  = reshape_fortran(log_qZ_y,  (batch_size,K2))\n",
    "        log_qM_Z  = reshape_fortran(log_qM_Z,  (batch_size,K2))\n",
    "        log_qa_My = reshape_fortran(log_qa_My, (batch_size,K2))\n",
    "        alphas_sup = reshape_fortran(alphas_sup, (self.P,batch_size,K2))\n",
    "        \n",
    "        \n",
    "        # now store the log probs of the spervised part\n",
    "        log_probs_sup = {'log_py_Ma':log_py_Ma, 'log_pM_Z':log_pM_Z,\n",
    "                         'log_pZ':log_pZ, 'log_qZ_y':log_qZ_y,\n",
    "                         'log_qM_Z':log_qM_Z, 'log_qa_My':log_qa_My, 'log_pa':log_pa}\n",
    "        \n",
    "        # finally, store the alphas to regularize later\n",
    "        alphas_all = {'alphas_unsup':alphas_unsup, 'alphas_sup':alphas_sup}\n",
    "        \n",
    "        return log_probs_unsup, log_probs_sup, omegas_nrmlzd, log_omegas, alphas_all\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def my_loss_function(log_probs_unsup, log_probs_sup, omegas_nrmlzd, log_omegas, alphas_all):\n",
    "    llambda = my_llambda; # regularization between supervised and unsupervised part\n",
    "    bbeta   = 10; # extra regularization (high likelihood of endmembers and abundances training data in the posterior)\n",
    "    tau     = my_tau; # extra extra regularization (sparsity)\n",
    "    lamb_We = my_lamb_We; # penalizes network weights of nonlinear encoder\n",
    "    lamb_Wd = my_lamb_Wd; # penalizes network weights of nonlinear decoder\n",
    "    \n",
    "    K1 = log_probs_unsup['log_py_Ma'].shape[1]\n",
    "    K2 = omegas_nrmlzd.shape[1]\n",
    "    batch_size = omegas_nrmlzd.shape[0]\n",
    "    \n",
    "    # unsupervised part of the cost function --------------\n",
    "    cost_unsup = 0\n",
    "    for i in range(0,batch_size):\n",
    "        for j in range(0,K1):\n",
    "            # terms in the numerator\n",
    "            cost_unsup = cost_unsup + log_probs_unsup['log_py_Ma'][i,j] \n",
    "            cost_unsup = cost_unsup + log_probs_unsup['log_pa'][i,j]\n",
    "            cost_unsup = cost_unsup + log_probs_unsup['log_pM_Z'][i,j] \n",
    "            cost_unsup = cost_unsup + log_probs_unsup['log_pZ'][i,j]\n",
    "            # terms in the denominator\n",
    "            cost_unsup = cost_unsup - log_probs_unsup['log_qa_My'][i,j]\n",
    "            cost_unsup = cost_unsup - log_probs_unsup['log_qM_Z'][i,j]\n",
    "            cost_unsup = cost_unsup - log_probs_unsup['log_qZ_y'][i,j]\n",
    "            \n",
    "    # supervised part of the cost function  \n",
    "    cost_sup = 0\n",
    "    for i in range(0,batch_size):\n",
    "        for j in range(0,K2):\n",
    "            temp = 0\n",
    "            # terms in the numerator\n",
    "            temp = temp + log_probs_sup['log_py_Ma'][i,j] \n",
    "            temp = temp + log_probs_sup['log_pa'][i,j] \n",
    "            temp = temp + log_probs_sup['log_pM_Z'][i,j] \n",
    "            temp = temp + log_probs_sup['log_pZ'][i,j] \n",
    "            # terms in the denominator\n",
    "            temp = temp - log_probs_sup['log_qa_My'][i,j] \n",
    "            temp = temp - log_probs_sup['log_qM_Z'][i,j] \n",
    "            temp = temp - log_probs_sup['log_qZ_y'][i,j] \n",
    "            # importance weight normalization (the omegas are already normalized now)\n",
    "            temp = omegas_nrmlzd[i,j] * temp\n",
    "            # accumulate in the cost function\n",
    "            cost_sup = cost_sup + temp\n",
    "            \n",
    "    # regularization term\n",
    "    cost_reg = 0\n",
    "    for i in range(0,batch_size):\n",
    "        for j in range(0,K2):\n",
    "            cost_reg = cost_reg + log_probs_sup['log_qa_My'][i,j] \n",
    "            cost_reg = cost_reg + log_omegas[i,j]\n",
    "    \n",
    "    # yet another regularization term (sparsity on alphas)\n",
    "    cost_reg_sprs = 0\n",
    "    for i in range(0,batch_size):\n",
    "        # this one computes it over the unsupervised data\n",
    "        for j in range(0,K1):\n",
    "            cost_reg_sprs = cost_reg_sprs + torch.linalg.norm(alphas_all['alphas_unsup'][:,i,j], ord=0.5) / K1\n",
    "        # this one computes it over the supervised data\n",
    "        for j in range(0,K2):\n",
    "            cost_reg_sprs = cost_reg_sprs + torch.linalg.norm(alphas_all['alphas_sup'][:,i,j], ord=0.5) / K2\n",
    "    \n",
    "    \n",
    "    # regularizes nonlinear mixing weights\n",
    "    reg_nlin_d_weights = 0\n",
    "    for param in model.fcy_Ma_nlin.parameters():\n",
    "        reg_nlin_d_weights = reg_nlin_d_weights + torch.norm(param, p=\"fro\")\n",
    "    \n",
    "    reg_nlin_e_weights = 0\n",
    "    for param in model.fca_My_alphas.parameters():\n",
    "        reg_nlin_e_weights = reg_nlin_e_weights + torch.norm(param, p=\"fro\")    \n",
    "        \n",
    "    \n",
    "    # now the total cost functions\n",
    "    cost = cost_unsup/K1 + llambda * cost_sup/K2 + (1+bbeta) * cost_reg/K2 \\\n",
    "           - tau * cost_reg_sprs - lamb_We * reg_nlin_e_weights - lamb_Wd * reg_nlin_d_weights\n",
    "    return -cost # maximize cost\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train(epoch, train_loader):\n",
    "    log_interval = 10 # how many batches to wait before logging training status    \n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    # get one batch from supervised data and from unsupervised data\n",
    "    for batch_idx, alldata in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        log_probs_unsup, log_probs_sup, omegas_nrmlzd, log_omegas, alphas_all = model(alldata)\n",
    "        loss = my_loss_function(log_probs_unsup, log_probs_sup, omegas_nrmlzd, log_omegas, alphas_all)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(alldata), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.item() / len(alldata)))\n",
    "    \n",
    "    avg_loss = train_loss / len(train_loader.dataset)\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, avg_loss))\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def test(epoch, train_loader):\n",
    "    model.eval()\n",
    "    A_est_out, Mn_est_out, M_avg_out, Y_rec_out, a_nlin_deg_out = [],[],[],[],[]\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, x_data in enumerate(train_loader):\n",
    "            y_unsup = x_data[0].to(device) # batch * L\n",
    "            y_sup = x_data[1][0].to(device) # batch * L\n",
    "            M_sup = x_data[1][1].to(device)\n",
    "            a_sup = x_data[1][2].to(device)\n",
    "            A_est, Mn_est, M_avg, Y_rec, a_nlin_deg = model.unmix(y_unsup.T)\n",
    "            ## Save\n",
    "            A_est_out.append(A_est)\n",
    "            Mn_est_out.append(Mn_est)\n",
    "            M_avg_out.append(M_avg)\n",
    "            Y_rec_out.append(Y_rec)\n",
    "            a_nlin_deg_out.append(a_nlin_deg)\n",
    "\n",
    "            \n",
    "        # Y = torch.zeros((L,N))\n",
    "        # for i in range(N):\n",
    "        #     Y[:,i] = train_loader.dataset.data_unsup[i]\n",
    "    print(f\"sahpe A_est_out {A_est_out[0].shape}\")\n",
    "    print(f\"sahpe M_avg_out {M_avg_out[0].shape}\")\n",
    "    print(f\"sahpe Mn_est_out {Mn_est_out[0].shape}\")\n",
    "    print(f\"sahpe Y_rec_out {Y_rec_out[0].shape}\")\n",
    "\n",
    "    A_est_out = torch.concatenate(A_est_out, axis=1)\n",
    "    Mn_est_out = torch.concatenate(Mn_est_out, axis=-1)\n",
    "    \n",
    "    #M_avg_out = torch.tensor(M_avg_out)\n",
    "    #print(f\"sahpe M_avg_out --- {M_avg_out.shape}\")\n",
    "    \n",
    "    Y_rec_out = torch.concatenate(Y_rec_out, axis=-1).T\n",
    "    a_nlin_deg_out = torch.concatenate(a_nlin_deg_out, axis=0).T\n",
    "\n",
    "    print(f\"sahpe A_est_out {A_est_out.shape}\")\n",
    "    print(f\"sahpe Mn_est_out {Mn_est_out.shape}\")\n",
    "    print(f\"sahpe Y_rec_out {Y_rec_out.shape}\")\n",
    "\n",
    "    return  A_est_out, Mn_est_out, M_avg_out, Y_rec_out, a_nlin_deg_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220785b2-9b55-4aa2-9049-48e2ce14f805",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for epochs_ in [10]:\n",
    "        #print(f'Experiement {k}')\n",
    "        # select example number and parameters    \n",
    "        EX_NUM = 2\n",
    "        exp_name = \"None\"\n",
    "        \n",
    "        if EX_NUM == 1: # DC1, synthetic data with nonlinear mixtures, BLMM\n",
    "            exp_name = \"DC1\"\n",
    "            my_llambda = 10\n",
    "            my_tau     = 0\n",
    "            my_lamb_We = 1e4\n",
    "            my_lamb_Wd = 0.001\n",
    "            \n",
    "        if EX_NUM == 2: # DC2, synthetic data with endmember variability\n",
    "            exp_name = \"synthetic\"\n",
    "            my_llambda = 1\n",
    "            my_tau     = 0.005\n",
    "            my_lamb_We = 0.01\n",
    "            my_lamb_Wd = 0.1\n",
    "            \n",
    "        if EX_NUM == 3: # real Samson image\n",
    "            exp_name = \"Samson\"\n",
    "            my_llambda = 1\n",
    "            my_tau     = 0.005\n",
    "            my_lamb_We = 0.01\n",
    "            my_lamb_Wd = 0.1\n",
    "            \n",
    "        if EX_NUM == 4: # real Jasper Ridge image\n",
    "            exp_name = \"Jasper\"\n",
    "            my_llambda = 1\n",
    "            my_tau     = 0\n",
    "            my_lamb_We = 0.01\n",
    "            my_lamb_Wd = 0.1\n",
    "        \n",
    "        if EX_NUM == 5: # real Cuprite image\n",
    "            exp_name = \"Cuprite\"\n",
    "            my_llambda = 10\n",
    "            my_tau     = 0.1\n",
    "            my_lamb_We = 0.05\n",
    "            my_lamb_Wd = 5\n",
    "            \n",
    "        if EX_NUM == 6: # real Huston image\n",
    "            exp_name = \"Houston\"\n",
    "            my_llambda = 10\n",
    "            my_tau     = 0.1\n",
    "            my_lamb_We = 0.05\n",
    "            my_lamb_Wd = 5\n",
    "            \n",
    "        \n",
    "        train_loader = torch.utils.data.DataLoader(dataset_maker(data_opt=EX_NUM), batch_size=256, shuffle=False)\n",
    "        test_loader = torch.utils.data.DataLoader(dataset_maker(data_opt=EX_NUM), batch_size=1, shuffle=False)\n",
    "\n",
    "        L = train_loader.dataset.data_sup[0][1].shape[0]\n",
    "        P = train_loader.dataset.data_sup[0][1].shape[1]\n",
    "        N = len(train_loader.dataset.data_unsup)\n",
    "        nr, nc = train_loader.dataset.A_u_cube.shape[0], train_loader.dataset.A_u_cube.shape[1]\n",
    "        H = 2 # dimension of the latent EM space\n",
    "\n",
    "        _str = f\"L:{L}, P:{P}, N:{N}, nr:{nr}, nc:{nc}, H:{H}\"\n",
    "        with open(\"/tsi/data_education/Ladjal/koublal/open-source/IDNet/results/metrics_ex\" + str(train_loader.dataset.data_opt) + \".txt\", \"a\") as text_file:\n",
    "            print(_str, file=text_file)\n",
    "        \n",
    "        model = IDNet(P, L, H=H).to(device)    \n",
    "        optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "        scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        num_epochs = epochs_; # number of epochs to train\n",
    "        loss_old = 1e30\n",
    "        for epoch in range(1, num_epochs + 1):\n",
    "            loss_t = train(epoch, train_loader)\n",
    "            A_est, Mn_est, Y_rec, a_nlin_deg, M_avg = test(epoch, test_loader)\n",
    "            \n",
    "            print(f\"train_loader.dataset.A_u shape: {train_loader.dataset.A_u.shape}, {A_est.shape}\")\n",
    "            print(f\"train_loader.dataset.M_u_ppx shape: {train_loader.dataset.M_u_ppx.shape}, {Mn_est.shape}\")\n",
    "            #print(f\"train_loader.dataset.Y shape: {train_loader.dataset.Y.shape}, {Y_rec.shape}\")\n",
    "            # compute metrics -----------------------\n",
    "            RMSE_A, NRMSE_A = compute_metrics(train_loader.dataset.A_u, A_est)\n",
    "            RMSE_M, NRMSE_M = compute_metrics(train_loader.dataset.M_u_ppx, Mn_est)\n",
    "            #Y_rec = Y_rec.tolist()\n",
    "            RMSE_Y, NRMSE_Y = compute_metrics(torch.tensor(train_loader.dataset.Y), Y_rec)\n",
    "            \n",
    "            metrics_str = '====> EPOCH: {:d}, Abundance NRMSE: {:.6f}, Endmember NRMSE: {:.6f}'.format(epoch, NRMSE_A, NRMSE_M)\n",
    "            with open(\"/tsi/data_education/Ladjal/koublal/open-source/IDNet/results/metrics_ex\" + str(train_loader.dataset.data_opt) + \".txt\", \"a\") as text_file:\n",
    "                print(metrics_str, file=text_file)\n",
    "                print(metrics_str) # print to console too\n",
    "            \n",
    "            if epoch <= 10:\n",
    "                scheduler.step() # reduce from 1e-3 to 1e-4 in 10 epochs with rate approx 0.8\n",
    "            \n",
    "            # check stopping condition\n",
    "            if abs(loss_t - loss_old) / abs(loss_t) < 1e-2:\n",
    "                break\n",
    "            loss_old = loss_t\n",
    "        elapsed_time = time.time()-start_time\n",
    "        \n",
    "        \n",
    "        # plot abundances and average EMs ----------------------------------\n",
    "        plotAbunds(A_est, nr=nr, nc=nc, \n",
    "                        thetitle='learned abundances',\n",
    "                        savepath='/tsi/data_education/Ladjal/koublal/open-source/IDNet/results/a_est_ex'+ str(train_loader.dataset.data_opt) +'test_bugs.pdf')\n",
    "        \n",
    "        plotEMs(M_avg, thetitle='learned avg EMs', savepath='/tsi/data_education/Ladjal/koublal/open-source/IDNet/results/EMs_est'+ str(train_loader.dataset.data_opt) +'test_bugs.pdf')\n",
    "        \n",
    "        # compare results to ground truth abundances if available\n",
    "        show_ground_truth(A_true=train_loader.dataset.A_u, Mgt_avg=train_loader.dataset.M_u_avg, nr=nr, nc=nc)\n",
    "        \n",
    "        torch.save(model.state_dict(), \"/tsi/data_education/Ladjal/koublal/open-source/IDNet/results/model_bugs.pth\")\n",
    "        \n",
    "        print('====> FINAL: Abundance NRMSE: {:.6f}, Endmember NRMSE: {:.6f}'.format(NRMSE_A, NRMSE_M))\n",
    "        print('====> Elapsed time: {:.6f}'.format(elapsed_time))\n",
    "        # plt.figure(), plt.plot(Mn_est[:,0,0:20]), plt.show();\n",
    "        # save .mat file with the results\n",
    "        # print(\"A_est\", A_est.shape)\n",
    "        # print(\"Mn_est\", Mn_est.shape)\n",
    "        # print(\"Y_rec\", Y_rec.shape)\n",
    "\n",
    "        \n",
    "        savemat(f'/tsi/data_education/Ladjal/koublal/open-source/IDNet/results_finale/results_{exp_name}_{num_epochs}'+ '.mat', \n",
    "                {'A_est':A_est.numpy(),\n",
    "                'Mn_est':Mn_est.numpy(),\n",
    "                'A_true':train_loader.dataset.A_u.numpy(),\n",
    "                'Mn_true':train_loader.dataset.M_u_ppx.numpy(),\n",
    "                'Y_rec':Y_rec.numpy(),\n",
    "                'a_nlin_deg':a_nlin_deg.numpy(),\n",
    "                'L':L, \n",
    "                'P':P,\n",
    "                'N':N,\n",
    "                'nr':nr,\n",
    "                'nc':nc,\n",
    "                'H':H\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1305ddc0-776b-4557-8e52-97c8857ebd5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c6f0e6-5e12-4a1a-966e-1cd85912c870",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaa4d31-5be8-43a7-86f5-5cadd4cdc875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c37094-cf00-4f9a-9591-ba214213951e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad525fe-ccf6-4b45-abff-7e2c45a30385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "our_result_dir = \"/tsi/data_education/Ladjal/koublal/open-source/NH_v2/resutls/Synthetic_Variability/outputs/\"\n",
    "our_abundance = np.load(our_result_dir+\"abundance.npy\", allow_pickle=True)\n",
    "our_endmemebers = np.load(our_result_dir+\"endmemebers.npy\", allow_pickle=True)\n",
    "our_y_hat_dirichlet = np.load(our_result_dir+\"y_hat_dirichlet.npy\", allow_pickle=True)\n",
    "our_y_hat_gen = np.load(our_result_dir+\"y_hat_gen.npy\", allow_pickle=True)\n",
    "our_y_trues = np.load(our_result_dir+\"y_trues.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc5231e5-8c24-469a-9db4-873fb39256e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_abundance(A, nr, nc,\n",
    "                   colorscale = \"rainbow\", \n",
    "                   thetitle: list = None,\n",
    "                   savepath : str =None):\n",
    "    \n",
    "    ''' plots abundance maps, should be P by N '''\n",
    "    P = A.shape[0] # number of endmembers\n",
    "    N = A.shape[1] # number of pixels\n",
    "    A_cube = np.reshape(np.transpose(A), (nc, nr, P))\n",
    "    fig, axs = plt.subplots(1, P, figsize=(20,5))\n",
    "    for i in range(P):\n",
    "        axs[i].imshow(A_cube[:,:,i].T, cmap=colorscale, vmin=0, vmax=1) #cmap='gray'\n",
    "        axs[i].axis('off')\n",
    "        if thetitle:\n",
    "            axs[i].set_title(thetitle[i], fontsize=12)\n",
    "    if savepath is not None: # save a figure is specified\n",
    "        plt.savefig(savepath, dpi=300, format='pdf')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_endmembers(endmembers, thetitle='Endmembers', savepath=None):\n",
    "    P = endmembers.shape[1]  # number of endmembers\n",
    "    L = endmembers.shape[0]  # number of bands\n",
    "\n",
    "    fig, axes = plt.subplots(1, P, figsize=(20, 5), sharex=True)\n",
    "\n",
    "    for i in range(P):\n",
    "        axes[i].plot(np.linspace(1, L, L), endmembers[:, i])\n",
    "        axes[i].set_ylabel(f'Endmember {i + 1}')\n",
    "\n",
    "    plt.xlabel('Band')\n",
    "    plt.suptitle(thetitle, fontsize=12)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if savepath is not None:  # save a figure if specified\n",
    "        plt.savefig(savepath, dpi=300, format='pdf')\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd78d40d-39a4-4339-8489-14a7ce2ecca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SynthVaria\n",
    "# N:2500, nr:50, nc:50, H:2, L:162, P:5\n",
    "#plot_abundance(data['A_est'], nr=50, nc=50, thetitle=None, savepath=None) #(A, nr, nc, thetitle='', savepath=None)\n",
    "plot_abundance(our_abundance, nr=50, nc=50, thetitle=None, savepath=None) #(A, nr, nc, thetitle='', savepath=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1364d1-e659-4d08-b678-b2c635a3d44d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-nilm",
   "language": "python",
   "name": "torch-nilm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
